\section{Conclusion}
이번 프로젝트를 통하여 \cite{xie2020selftraining} 논문에 있는 teacher-noisy student models self-training을 CIFAR-10 데이터셋에 대해 구현해보았다. 논문에 나오는 내용과 더불어 label smoothing, mixup과 같은 응용적인 pseudo label 생성 방법을 적용해보았으며, 학습된 모델 결과를 여러 지표에 따라 분석해볼 수 있었다. 그 과정에서 label smoothing, mixup이 FGSM과 같은 adversarial attack에 강직하며, mixup은 relative mCE 수치가 가장 뛰어나 오염에 강직하다는 사실을 알게 되었다. 또한 초기 labeled data의 비율이 높을수록 더 뛰어난 모델을 학습할 수 있음을 깨달았으며, CIFAR-10과 같이 전체 이미지 수가 적은 경우에 대해서는 데이터 labeling 중노동이 의미있는 효과를 불러준다는 사실을 알 수 있었다.

하지만 CIFAR-10 데이터셋의 부족한 이미지 수와 비교적 작은 규모의 학습 네트워크로부터 여러 한계점을 관찰하기도 했다. Label smoothing이나 mixup을 사용하는 경우 overconfident 문제를 해결할 수 있지만, confidence threshold를 넘어가는 이미지 수가 적어져 많은 수의 pseudo label을 확보하기 어려웠다. 때문에 mixup은 hard label 이외 다른 방식과 결합하여 사용하는데 지장이 있었다. 그렇다고 confidence threshold를 조정하니 신뢰도가 낮은 저품질 데이터를 인수받거나 학습 데이터가 적어지는 등의 tradeoff가 명확히 드러났다. 모델 네트워크의 규모가 작아 model noise가 오히려 악영향을 주는 사태가 관찰되었으나, 신기하게도 student에 모든 noise를 제거하니 오히려 가장 낮은 성능이 나타나 `noisy student'라는 단어의 정당성을 확인하기도 하였다. 만약 STL-10과 같이 준 지도학습 목적으로 만들어진 큰 규모의 데이터셋을, 더 큰 네트워크 모델로, 더 많은 teacher-noisy student 연결로써 학습했다면 원 논문에 가까운 이상적인 결과를 얻어낼 수 있었을 것 같지만, 시간과 자원의 한계로 인해 그러지 못했던 사실이 아쉬웠다. 또한 같은 CIFAR-10 준 지도학습 데이터셋으로부터 다른 방식으로 학습한 모델과 여러 지표를 비교한다면 더 객관적인 분석이 가능했을 것 같지만(Robustness 향상이 self training 덕분인지, noise injection 덕분인지 구분하기 등), 같은 이유로 수행하지 못해서 아쉬웠다.

처음으로 toy model에서 벗어나 제대로 돌려본 딥러닝 프로젝트였다. PyTorch 코드를 이렇게까지 사용해본적은 여태껏 없었다. 정말 사소한 것 하나 하나로 학습의 완성도가 크게 갈렸다. Optimizer의 종류, learning rate, 그리고 가장 중요한 scheduler 문제 때문에 초반에 엄청 고역을 겪었다. 여러 시행착오 끝에 감을 잡고나서 내 개인 소유의 데스크탑(AMD Ryzen 3700X, RTX 2070 Super)으로 학습을 돌렸는데, teacher를 제외하고 ResNet-26, 32, 38에 해당하는 student 학습시키는데만 약 3시간 정도의 시간이 소요되었다. 또한 학습이 끝난 뒤 이를 분석하는데도 많은 시간이 들어갔다. 특히 CIFAR-10-P의 경우 데이터 크기만 18GB가 넘어갔기 때문이다. 한 모델을 분석하는데 약 10분 정도가 소요되었다. 온갖 가설을 세우고 검증하느라 약 40세트의 student model을 학습해서, \texttt{run\_train.sh}, \texttt{run\_test.sh} 스크립트가 5-6일 내내 침대 옆에서 돌아가 따로 난방을 켜지 않아도 방 안이 따뜻해 좋았다. 프로젝트 코드를 직접 구현하는 과정에서 adversarial attack, calibration error, corruption robustness 등 내가 잘 몰랐던 개념들을 습득하게 되었으며, 딥러닝 코드에 대한 (특히 텐서 연산) 커다란 매력을 알게 되어 재미있었다. 정말 보람찬 프로젝트였다.