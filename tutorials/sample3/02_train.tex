\section{Training Method}
\subsection{Basic Dataset Settings}
처음 학습 데이터는 10\%(5,000장)만 label을 남기고, 나머지 90\%(45,000장)는 unlabeled set으로 두어 진행하였다. 기본적인 모델 구조나 학습 방법은 \cite{xie2020selftraining}를 따라갔다. 초기 teacher model은 가장 작은 규모의 네트워크(ResNet-20)로 설정했으며, noisy student는 ResNet-26에서 32, 38 순서로 규모가 커진다. 다음 단계 student는 이전 단계 (student) model을 teacher로 삼아서 학습한다.

처음 생성된 teacher model은 10\%의 labeled training data만 가지고 model noise 없이 RandAugment 처리된 데이터만으로 학습한다. 이는 비교적 규모가 작았던 ResNet-20 네트워크 모델에 model noise를 넣었더니, underfitting 문제가 심각하게 발생하여 제대로 학습되지 않았기 떄문이었다. Teacher model의 학습이 끝난 뒤, unlabeled training data에 대해 생산한 logits의 softmax 값을 각 클래스에 대한 confidence로 간주하여, 이를 pseudo label을 제작하는데 사용한다.

\subsection{Pseudo Labels Generated by Teacher Model}
이 pseudo label을 만드는 여러 가지 방법이 있다. 우선 \cite{xie2020selftraining}에서는 argmax를 계산하여 0/1만 표기하는 hard label과, teacher model이 생산한 confidence 그 자체를 사용하는 soft label이 소개되어있었다. 선술한 바와 같이 adversarial attack 등에 강직한 label smoothing과 mixup 방법도 적용해보았다. Label smoothing이란 가장 confidence가 높은 클래스에 $1 - \epsilon$ 값을 부여하고, 나머지 클래스들에게는 $\epsilon / (\text{num\_class} - 1)$ 값을 두는 방식이다. \cite{szegedy2015rethinking} 실제로 dataset에 label이 잘못되었을 가능성을 염두해두고 설계한 방식이므로, teacher의 pseudo label에 의지하는 본 프로젝트에서 아주 유망할 것으로 예측했다.

Mixup은 여러 이미지를 혼합한 한 장의 새로운 이미지를 만들고, 거기에 상응하는 라벨을 만드는 방식이다. \cite{zhang2018mixup} 나는 beta 분포로 가중치 값 $\lambda \in (0, 1)$을 하나 생성하여, 두 이미지 $\vec x_1$과 $\vec x_2$, 그리고 onehot 인코딩된 (pseudo) label $y_1$과 $y_2$를

\begin{align*}
  \lambda &\sim \operatorname{Beta}(1, 1)\\
  \vec x_{mixup} &= \lambda \vec x_1 + (1 - \lambda) \vec x_2 \\
  y_{mixup} &= \lambda y_1 + (1 - \lambda) y_2
\end{align*}

으로 처리하는 방식으로 구현하였다. 여기서 label은 onehot 인코딩 형식의 shape을 가지기만 하면 정당하게 가산적으로 합칠 수 있으므로, hard, soft, label smoothing 방식과 모두 결합할 수 있었다.

또한 teacher model은 완전히 신뢰할 수 없으므로, 최고로 높은 클래스에 대한 confidence가 일정 threshold ($\geq 0.8$) 이상을 충족하는 unlabeled data만 필터링하여 다음 noisy student의 학습 데이터로 사용하였다. 이 경우 분류기가 혼돈하기 쉬운 클래스(개와 고양이)에 대해 confidence level이 낮아, 선발된 이미지의 장 수가 클래스마다 편차가 커지는 문제가 발생하였다. 이를 보정하기 위해, 각 클래스별 training data 수가 최소 4,000장(전체 5,000장) 이상이 되도록, 기존에 있는 이미지를 복제하는 방식으로 data balancing을 구현했다. 여기서 이미지 복제는 $(1)$ labeled data를 최우선으로, $(2)$ teacher model이 높은 confidence level을 표하는 순으로 우선순위를 두었다. 또한 teacher model의 오분류로 인해 한 클래스의 이미지가 너무 많아지는 경우(최소 클래스 이미지 장 수보다 1,000장 초과) 또한, confidence가 낮은 데이터부터 누락시키는 방식으로써 균형을 맞추었다.

\subsection{Noisy Student Model}
Model noise에는 ResNet 구조에 알맞게 stochastic depth를 넣었으며, 마지막 fully-connected layer에 dropout도 넣었다. Input data noise는 \cite{cubuk2019randaugment}에 있는 RandAugment 방식을 사용하였다. \cite{xie2020selftraining}에 있는 매개변수를 차용하여 stochastic depth는 말단 0.8로 decay하는 방식으로, dropout은 $p=0.5$로, RandAugment는 magnitude $27$로 설정하여 학습하였다.

\subsection{Training Settings}
Teacher는 한 epoch에 5,000장의 이미지를 보는 한편, student는 최소 40,000장을 이미지를 본다. 또한, confidence level에 따라 생성된 pseudo labeled training data의 수는 매번 달라진다. 그러므로 모든 단계를 동등한 수의 epoch로 학습하는 것은 공정하지 않다. 그래서 나는 ``학습 과정에 사용하는 이미지의 장 수''를 일정하게 두는 방식으로 공정성을 확보했다. 비교적 적은 data로 학습하는 teacher model의 경우 5,000,000장의 이미지를 돌도록 설정했다. Model noise가 많이 들어간 noisy student model의 경우 15,000,000장의 이미지를 돌도록 설정했다. 각각 full training set(50,000장) 기준으로 100, 300 epochs에 해당하는 수다.

SGD optimizer를 사용했으며, learning rate은 초기 0.1, momentum은 0.9, weight decay는 $10^{-4}$로 설정했다. Learning rate scheduler는 ResNet과 CIFAR-10에 효과적인 성능을 보여줬던 multistep scheduler를 사용했다. 전체 epoch의 50\%, 75\%에 도달했을 때, learning rate가 10배씩 (0.01, 0.001) 감소한다.